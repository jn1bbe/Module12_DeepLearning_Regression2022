{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Module 12_DeepLearning_Regression2022.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"3utp-S1ay5r8"},"source":["#**Module 12: Neural Networks and Deep Learning--Regression**\n","Imagine you have lots of data--Big Data, as in 1,000,000 tuples and more per day--and need to build a classification system with utmost reliability because if you're wrong, the consequences may be detrimental to people or property. Would you use a simple tree? Or a k Nearest Neighbor? Or a Random Forest? Or would you want a system that combines a number of self-optimizing algorithm runs with an element of randomization and voting in order to give you the most reliable output? \n","\n","That, then would be a Deep Learning Network. **Deep Learning means nothing more than a Neural Network with multiple hidden layers,** in which data is summarized and analyzed and summarized and analyzed and so on. These pictures say it all:\n","\n","**A Simple Neural Network**\n","<div>\n","<center>\n","<img src=\"https://raw.githubusercontent.com/shstreuber/Data-Mining/master/images/simplenn_regression.png\" width=\"350\">\n","</div>\n","\n","**A Deep Neural Network**\n","<div>\n","<center>\n","<img src=\"https://raw.githubusercontent.com/shstreuber/Data-Mining/master/images/deepnn_regression.png\" width=\"600\">\n","</div>\n","\n","At the end of this module, you will be able to:\n","\n","* Configure 2 simple and 2 deep learning Regression Networks \n","* Describe how a Deep Neural Network works\n","* Configure TensorFlow and Keras\n","* Solve a simple Deep Learning problem\n","* Compare regular Neural Network output with Deep Learning output\n","\n","To get started, please watch this instructor video:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":336},"id":"zHb5bE3czqhH","executionInfo":{"status":"ok","timestamp":1648860330366,"user_tz":240,"elapsed":319,"user":{"displayName":"Sonja Streuber","userId":"03872648719424952237"}},"outputId":"5e6374e1-d9e3-483a-a0e8-60bbb8383812"},"source":["from IPython.display import HTML\n","HTML('<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/RkiTL_T8VsY\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/RkiTL_T8VsY\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"]},"metadata":{},"execution_count":2}]},{"cell_type":"markdown","metadata":{"id":"GzT4W7L3zg5E"},"source":["#**What is Tensorflow?**\n","Essentially, TensorFlow (a Google product) is an end-to-end open source machine learning **platform**. As a platform, it contains a number of libraries, or packages, the most well-known of which is Keras.\n","\n","The **GOAL** of TensorFlow is to train and run deep neural networks for handwritten digit classification, image recognition, word embeddings, recurrent neural networks, sequence-to-sequence models for machine translation, natural language processing, and PDE (partial differential equation) based simulations.\n","\n","##**Sooooo ... what is a Tensor?**\n","The vocabulary here may sound technical and daunting, but there are a few very simple concepts hiding behind it. A Tensor is simply a multidimensional array:\n","\n","* Scalar = 0D Tensor\n","* Vector = 1D Tensor\n","* Matrix = 2D Tensor\n","* Cube = 3D Tensor\n","\n","Thereby, we can deduce that a 4-D tensor is a vector of cubes, 5-D tensor is a matrix of cubes, 6-D tensor is a cube of cubes, etc. Take a look at the graphic below:\n","\n","<div>\n","<center>\n","<img src=\"https://raw.githubusercontent.com/shstreuber/Data-Mining/master/images/tensor.png\" width=\"600\">\n","</div>\n","\n","##**And How does it Work?**\n","Working with TensorFlow is  basically like setting up any other Classification:\n","0. You set up your libraries and load your data\n","1. You do your EDA (Exploratory Data Analysis) to see how the data is distributed and to determine what the class attribute in the dataset should be. \n","2. Preprocess the data (remove n/a, transform data types as needed, deal with missing data) and THEN normalize the data so we can apply the model weights without problems.\n","3. Split the data into a training set and a test set\n","4. Build the model based on the training set\n","5. Test the model on the test set\n","6. Determine the quality of the model"]},{"cell_type":"markdown","metadata":{"id":"2x_5G4kA5BcJ"},"source":["#**0. Preparation and Setup**\n","To wrap our head around the process of setting up a Deep Learning model, we will work with a dataset with which we are already familiar: The adult dataset."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":224},"id":"PUbUl6Mg5RH_","executionInfo":{"status":"ok","timestamp":1648860381053,"user_tz":240,"elapsed":406,"user":{"displayName":"Sonja Streuber","userId":"03872648719424952237"}},"outputId":"b889efae-a131-47db-badb-a7187c53d62c"},"source":["import tensorflow as tf # This tells Colab that we are using TensorFlow\n","\n","from tensorflow import keras # This is the main TensorFlow library\n","from tensorflow.keras import layers # We are building a Neural Network with several hidden layers\n","from tensorflow.keras.layers.experimental import preprocessing\n","\n","print(\"Current TensorFlow version is\", tf.__version__)\n","\n","import numpy as np\n","import pandas as pd \n","import matplotlib.pyplot as plt\n","import seaborn as sns # for visualization\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","np.random.seed(42)\n","\n","#Reading in the data as adult dataframe\n","adult = pd.read_csv(\"https://raw.githubusercontent.com/shstreuber/Data-Mining/master/data/adult.data.simplified.csv\")\n","adult.head()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Current TensorFlow version is 2.8.0\n"]},{"output_type":"execute_result","data":{"text/plain":["   age         workclass  education  educationyears       maritalstatus  \\\n","0   39         State-gov  Bachelors              13       Never-married   \n","1   50  Self-emp-not-inc  Bachelors              13  Married-civ-spouse   \n","2   38           Private    HS-grad               9            Divorced   \n","3   53           Private       11th               7  Married-civ-spouse   \n","4   28           Private  Bachelors              13  Married-civ-spouse   \n","\n","          occupation   relationship   race     sex  hoursperweek  \\\n","0       Adm-clerical  Not-in-family  White    Male            40   \n","1    Exec-managerial        Husband  White    Male            13   \n","2  Handlers-cleaners  Not-in-family  White    Male            40   \n","3  Handlers-cleaners        Husband  Black    Male            40   \n","4     Prof-specialty           Wife  Black  Female            40   \n","\n","   nativecountry  incomeUSD  \n","0  United-States      43747  \n","1  United-States      38907  \n","2  United-States      25055  \n","3  United-States      26733  \n","4           Cuba      23429  "],"text/html":["\n","  <div id=\"df-3a918945-985d-475e-aac6-f2ceaf8d25df\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>age</th>\n","      <th>workclass</th>\n","      <th>education</th>\n","      <th>educationyears</th>\n","      <th>maritalstatus</th>\n","      <th>occupation</th>\n","      <th>relationship</th>\n","      <th>race</th>\n","      <th>sex</th>\n","      <th>hoursperweek</th>\n","      <th>nativecountry</th>\n","      <th>incomeUSD</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>39</td>\n","      <td>State-gov</td>\n","      <td>Bachelors</td>\n","      <td>13</td>\n","      <td>Never-married</td>\n","      <td>Adm-clerical</td>\n","      <td>Not-in-family</td>\n","      <td>White</td>\n","      <td>Male</td>\n","      <td>40</td>\n","      <td>United-States</td>\n","      <td>43747</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>50</td>\n","      <td>Self-emp-not-inc</td>\n","      <td>Bachelors</td>\n","      <td>13</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Exec-managerial</td>\n","      <td>Husband</td>\n","      <td>White</td>\n","      <td>Male</td>\n","      <td>13</td>\n","      <td>United-States</td>\n","      <td>38907</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>38</td>\n","      <td>Private</td>\n","      <td>HS-grad</td>\n","      <td>9</td>\n","      <td>Divorced</td>\n","      <td>Handlers-cleaners</td>\n","      <td>Not-in-family</td>\n","      <td>White</td>\n","      <td>Male</td>\n","      <td>40</td>\n","      <td>United-States</td>\n","      <td>25055</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>53</td>\n","      <td>Private</td>\n","      <td>11th</td>\n","      <td>7</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Handlers-cleaners</td>\n","      <td>Husband</td>\n","      <td>Black</td>\n","      <td>Male</td>\n","      <td>40</td>\n","      <td>United-States</td>\n","      <td>26733</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>28</td>\n","      <td>Private</td>\n","      <td>Bachelors</td>\n","      <td>13</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Prof-specialty</td>\n","      <td>Wife</td>\n","      <td>Black</td>\n","      <td>Female</td>\n","      <td>40</td>\n","      <td>Cuba</td>\n","      <td>23429</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3a918945-985d-475e-aac6-f2ceaf8d25df')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-3a918945-985d-475e-aac6-f2ceaf8d25df button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-3a918945-985d-475e-aac6-f2ceaf8d25df');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","metadata":{"id":"svkCY-1t54q2"},"source":["#**1. Exploratory Data Analysis**\n","How many rows does the adult dataset have? What are the attribute types? What is the mean, median, and mode of the incomeUSD attribute? \n","\n","These are all questions to solve. Use the code rows below to find the answers:"]},{"cell_type":"code","metadata":{"id":"6TXu6Ud8y0Ro"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cfx-mqha6c9z"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cmMYxX7x6dzF"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lwar0tYH0EAC"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"XYNfxVhB6efh"},"source":["# **2. Preprocessing**\n","As with the simple Neural Networks you have encountered already, preprocessing is a bit more involved than with, say, a Random Forest algorithm.\n","<div>\n","<center>\n","<img src=\"https://raw.githubusercontent.com/shstreuber/Data-Mining/master/images/TF_Process1.png\" width=\"600\">\n","</div>"]},{"cell_type":"markdown","metadata":{"id":"2uNkowDWq2ST"},"source":["##**2.1 Reducing the Data**\n"]},{"cell_type":"markdown","metadata":{"id":"oFNTyz36EXjJ"},"source":["##Your Turn\n","You have done this before with the insurance dataset: Build an adult_dl dataset consisting of age, educationyears, race, hoursperweek, and incomeUSD as the class attribute"]},{"cell_type":"code","metadata":{"id":"-BM-pAfg72wF","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1648860388859,"user_tz":240,"elapsed":154,"user":{"displayName":"Sonja Streuber","userId":"03872648719424952237"}},"outputId":"cecc08e5-4c88-447b-ffe6-c3c568b6e1ab"},"source":["adult_dl = pd.DataFrame(adult, columns = ['age', 'educationyears', 'race','hoursperweek','incomeUSD'])\n","adult_dl.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   age  educationyears   race  hoursperweek  incomeUSD\n","0   39              13  White            40      43747\n","1   50              13  White            13      38907\n","2   38               9  White            40      25055\n","3   53               7  Black            40      26733\n","4   28              13  Black            40      23429"],"text/html":["\n","  <div id=\"df-771c0c83-721a-4d0e-bd27-8a24887831e2\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>age</th>\n","      <th>educationyears</th>\n","      <th>race</th>\n","      <th>hoursperweek</th>\n","      <th>incomeUSD</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>39</td>\n","      <td>13</td>\n","      <td>White</td>\n","      <td>40</td>\n","      <td>43747</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>50</td>\n","      <td>13</td>\n","      <td>White</td>\n","      <td>13</td>\n","      <td>38907</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>38</td>\n","      <td>9</td>\n","      <td>White</td>\n","      <td>40</td>\n","      <td>25055</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>53</td>\n","      <td>7</td>\n","      <td>Black</td>\n","      <td>40</td>\n","      <td>26733</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>28</td>\n","      <td>13</td>\n","      <td>Black</td>\n","      <td>40</td>\n","      <td>23429</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-771c0c83-721a-4d0e-bd27-8a24887831e2')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-771c0c83-721a-4d0e-bd27-8a24887831e2 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-771c0c83-721a-4d0e-bd27-8a24887831e2');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","metadata":{"id":"ObVGq_Sg8C5N"},"source":["##**2.2 Preparing the Data for use with TensorFlow**\n","In this section, you will see that preparing data to work with a Deep Learning Neural Network requires the same kind of preprocessing that you have already encountered:\n","\n"]},{"cell_type":"markdown","metadata":{"id":"5P5EQ9M1w_7j"},"source":["### **2.2.1 Encoding Categorical Variables**\n","Did you remember that Neural Networks (regular **and** in TensorFlow) require only numeric data? Well ... \"race\" is quite obviously categorical, so we need to convert it to one-hot format. We do this with pd.dummies()"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"fsXwA597zKY4","executionInfo":{"status":"ok","timestamp":1648860391978,"user_tz":240,"elapsed":154,"user":{"displayName":"Sonja Streuber","userId":"03872648719424952237"}},"outputId":"de4b713d-420a-4d09-c90a-3e96acb5fa78"},"source":["adult_dl = pd.get_dummies(adult_dl, columns=['race'], prefix='', prefix_sep='')\n","adult_dl.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   age  educationyears  hoursperweek  incomeUSD  Amer-Indian-Eskimo  \\\n","0   39              13            40      43747                   0   \n","1   50              13            13      38907                   0   \n","2   38               9            40      25055                   0   \n","3   53               7            40      26733                   0   \n","4   28              13            40      23429                   0   \n","\n","   Asian-Pac-Islander  Black  Other  White  \n","0                   0      0      0      1  \n","1                   0      0      0      1  \n","2                   0      0      0      1  \n","3                   0      1      0      0  \n","4                   0      1      0      0  "],"text/html":["\n","  <div id=\"df-ede9d4fa-5205-4843-940f-ca445375773d\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>age</th>\n","      <th>educationyears</th>\n","      <th>hoursperweek</th>\n","      <th>incomeUSD</th>\n","      <th>Amer-Indian-Eskimo</th>\n","      <th>Asian-Pac-Islander</th>\n","      <th>Black</th>\n","      <th>Other</th>\n","      <th>White</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>39</td>\n","      <td>13</td>\n","      <td>40</td>\n","      <td>43747</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>50</td>\n","      <td>13</td>\n","      <td>13</td>\n","      <td>38907</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>38</td>\n","      <td>9</td>\n","      <td>40</td>\n","      <td>25055</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>53</td>\n","      <td>7</td>\n","      <td>40</td>\n","      <td>26733</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>28</td>\n","      <td>13</td>\n","      <td>40</td>\n","      <td>23429</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ede9d4fa-5205-4843-940f-ca445375773d')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-ede9d4fa-5205-4843-940f-ca445375773d button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-ede9d4fa-5205-4843-940f-ca445375773d');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"ZEmkap4x2HKb"},"source":["### **2.2.2 Splitting into Training and Test Set**\n","We will do this first since we will want to reduce the amount of data that we will have to normalize."]},{"cell_type":"code","metadata":{"id":"VDuoUaeU2Tfm"},"source":["train_dataset = adult_dl.sample(frac=0.8, random_state=0)\n","test_dataset = adult_dl.drop(train_dataset.index)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PefhBuEj2nHW"},"source":["### **2.2.3 Splitting Features from Labels**\n","Separate the target value, the \"label\", from the features. This label is the value that you will train the model to predict--in our case, we want to predict incomeUSD."]},{"cell_type":"code","metadata":{"id":"DOaQmB3L2vKj"},"source":["train_features = train_dataset.copy()\n","test_features = test_dataset.copy()\n","\n","train_labels = train_features.pop('incomeUSD')\n","test_labels = test_features.pop('incomeUSD')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tXou63hL1Gg_"},"source":["### **2.2.4 Normalizing**\n","Except for age and educationyears, which are both measured in years, all other variables are measured in **different units**. This also puts them on **different scales**. Since, in a Neural Network, we need all our values on the **same scale**, so that the weights can be applied uniformly, we need to normalize! One reason this is important is because the features are multiplied by the model weights. So the scale of the outputs and the scale of the gradients are affected by the scale of the inputs.\n","\n","The [**preprocessing.Normalization layer**](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/Normalization) is a clean and simple way to build that preprocessing into your model. And YES--by creating the normalization layer, you effectively just started building your TensorFlow model:"]},{"cell_type":"code","metadata":{"id":"u3zzDTud1vxI"},"source":["normalizer = preprocessing.Normalization(axis=-1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b1Mw1Ptl4KTp"},"source":["Now we apply the normalizer to the data:"]},{"cell_type":"code","metadata":{"id":"iFxkYAQs4N6V"},"source":["normalizer.adapt(np.array(train_features))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3b2bfnyc4Soc"},"source":["This calculates the mean and variance, and stores them in the layer."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iFuXKv-M4YL5","executionInfo":{"status":"ok","timestamp":1648860423646,"user_tz":240,"elapsed":26,"user":{"displayName":"Sonja Streuber","userId":"03872648719424952237"}},"outputId":"68ea3ebe-5b9b-4d1d-ecc7-93ab9ff217c2"},"source":["print(normalizer.mean.numpy())"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[3.8507965e+01 1.0091838e+01 4.0392166e+01 9.2134075e-03 3.2746013e-02\n","  9.5973052e-02 8.4840171e-03 8.5358381e-01]]\n"]}]},{"cell_type":"markdown","metadata":{"id":"twvUHFO_4hC3"},"source":["When the layer is called it returns the input data, with each feature independently normalized:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dqt9CbSR4iao","executionInfo":{"status":"ok","timestamp":1648860426067,"user_tz":240,"elapsed":160,"user":{"displayName":"Sonja Streuber","userId":"03872648719424952237"}},"outputId":"e0318ae9-f50e-4029-a586-b0d4398c3356"},"source":["first = np.array(train_features[:1])\n","\n","with np.printoptions(precision=2, suppress=True):\n","  print('Original data:', first)\n","  print()\n","  print('Normalized data:', normalizer(first).numpy())"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Original data: [[27 10 44  0  0  0  0  1]]\n","\n","Normalized data: [[-0.84 -0.04  0.29 -0.1  -0.18 -0.33 -0.09  0.41]]\n"]}]},{"cell_type":"markdown","metadata":{"id":"VS323LJk40_b"},"source":["# **3. Building the Models**\n","There is always a specific process with which to build a TensorFlow model:\n","<div>\n","<center>\n","<img src=\"https://raw.githubusercontent.com/shstreuber/Data-Mining/master/images/TF_Process2.png\" width=\"600\">\n","</div>\n","\n","1. First, we set up the **keras SEQUENTIAL MODEL**. This is the framework inside of which we are going to define the layers. Sequential = layers are sequentially next to each other (either “stacked” or left-to-right, depending on how you draw them).\n","---\n","2. Inside the Sequential model, we define the **LAYERS**. To do this, we need to know the following:\n","* **Shape**: This is the number of attributes we use as input for the model\n","---\n","3. In the next step, we define HOW we want the model to run, that is to **COMPILE**, with model.compile(). To do this, we need to know the following:\n","* **Optimizer** = gradient descent function (i.e. which function we use to optimize the step-down of the weights); adam = adaptive learning rate optimization algorithm\n","* **Loss Function**= evaluation of the ŷ vs the ground truth\n","* **Metrics** = evaluation criterion, here accuracy.\n","---\n","4. Then, we **FIT** the model to the training set with model.fit(). To do this, we need to know the following:\n","* **Epoch**: One Epoch is when an ENTIRE dataset is passed forward and backward through the neural network only ONCE. If one epoch is too big to feed to the computer at once we can divide it in several smaller batches\n","* **Batch size**: Depending on the number of needed features in your dataset (you should reduce these to NO MORE THAN 6), the computing effort can be too intense. Just like you would not each a whole sandwich in one bite, the machine does better when processing the data in smaller bites called batches. The standard batch size is 32.\n","---\n","5. Lastly (and in purple!), we use our model to **PREDICT** the values for the test set with model.predict()\n","---\n","**How we choose the LOSS FUNCTION** for step 3 depends on the type of calculation we need our Neural Network to perform:\n","* If the output variable is **continuous**, we are performing a regression, so the loss function is **mean squared error or MSE**\n","* If the output variable is **binary**, we are performing a classification, so the loss function is **binary_crossentropy**\n","* If the output variable is **categorical** with more than two labels, we are still performing a classification, but now the loss function is **categorical_crossentropy**\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Fi1HyF7z44HR"},"source":["##**3.1 REGRESSION: Using one Variable to predict incomeUSD in a Simple Neural Network**\n","We will use age to predict incomeUSD. To do so, we will use a keras.Sequential model. This model represents a sequence of steps. In this case there are two steps:\n","\n","1. Normalize the input ['age'].\n","2. Apply a linear transformation () to produce 1 output using layers.Dense.\n","\n","The number of inputs can either be set by the input_shape argument, or automatically when the model is run for the first time."]},{"cell_type":"code","metadata":{"id":"K-FrbA9NBRgK"},"source":["# First, we build the normalization layer:\n","age_new = np.array(train_features['age'])\n","\n","age_normalizer = preprocessing.Normalization(input_shape=[1,], axis=None)\n","age_normalizer.adapt(age_new)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zBgORl4A_M-3","executionInfo":{"status":"ok","timestamp":1648860432548,"user_tz":240,"elapsed":321,"user":{"displayName":"Sonja Streuber","userId":"03872648719424952237"}},"outputId":"2fe72557-c0a5-4d35-da98-07864343a644"},"source":["# Now we build the framework that holds all the models:\n","age_model = tf.keras.Sequential([\n","    age_normalizer,\n","    layers.Dense(units=1)\n","])\n","\n","age_model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," normalization_1 (Normalizat  (None, 1)                3         \n"," ion)                                                            \n","                                                                 \n"," dense (Dense)               (None, 1)                 2         \n","                                                                 \n","=================================================================\n","Total params: 5\n","Trainable params: 2\n","Non-trainable params: 3\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","metadata":{"id":"Uc5_BniXDdSU"},"source":["Now we can configure the training procedure using the Model.compile() method. The most important arguments to compile are the loss and the optimizer since these define what will be optimized (mean_absolute_error) and how (using the [optimizers.Adam](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam))."]},{"cell_type":"code","metadata":{"id":"7zL3vNLLDiO3"},"source":["age_model.compile(\n","    optimizer=tf.optimizers.Adam(learning_rate=0.1),\n","    loss='mean_absolute_error')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d1AxoAvHDtqa"},"source":["Once the model is configured, we use Model.fit() to train it (give this about 1-2 minutes):"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jCFlvfrMDiWs","executionInfo":{"status":"ok","timestamp":1648860521235,"user_tz":240,"elapsed":84090,"user":{"displayName":"Sonja Streuber","userId":"03872648719424952237"}},"outputId":"9cc41017-2e58-436d-d730-c8ef571095e5"},"source":["%%time\n","history = age_model.fit(\n","    train_features['age'], train_labels,\n","    epochs=100,\n","    # suppress logging\n","    verbose=0,\n","    # Calculate validation results on 20% of the training data. Validation means that we test as we go, on a 20% subset of the training data\n","    validation_split = 0.2)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["CPU times: user 1min 36s, sys: 6.17 s, total: 1min 42s\n","Wall time: 1min 23s\n"]}]},{"cell_type":"code","source":["train_features['age']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y8ueGxNLwwiL","executionInfo":{"status":"ok","timestamp":1648860807688,"user_tz":240,"elapsed":174,"user":{"displayName":"Sonja Streuber","userId":"03872648719424952237"}},"outputId":"dffe7457-02c0-404c-bc48-9fd46d64dfb3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["22278    27\n","8950     27\n","7838     25\n","16505    46\n","19140    45\n","         ..\n","12877    36\n","13288    28\n","2751     55\n","11903    34\n","17632    48\n","Name: age, Length: 26049, dtype: int64"]},"metadata":{},"execution_count":27}]},{"cell_type":"markdown","metadata":{"id":"0eJIetubEUEY"},"source":["Visualize the model's training results (you must run the code fields to see the graph):"]},{"cell_type":"code","metadata":{"id":"EIOA_tsOAS_W"},"source":["x = tf.linspace(0.0, 250, 251)\n","y = age_model.predict(x)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j_IVJUMrAn0a","colab":{"base_uri":"https://localhost:8080/","height":279},"executionInfo":{"status":"ok","timestamp":1648860785035,"user_tz":240,"elapsed":636,"user":{"displayName":"Sonja Streuber","userId":"03872648719424952237"}},"outputId":"c433e1d6-fee6-4cf1-f952-7f5e09009826"},"source":["def plot_age(x, y):\n","  plt.scatter(train_features['age'], train_labels, label='Data')\n","  plt.plot(x, y, color='k', label='Predictions')\n","  plt.xlabel('age')\n","  plt.ylabel('incomeUSD')\n","  plt.legend()\n","plot_age(x,y) "],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"n-PrtMxmBUTj"},"source":["As you can see, the output here is abysmal. Let's see if we have better luck with the next model"]},{"cell_type":"markdown","metadata":{"id":"AFlI3cVH0maC"},"source":["##Your Turn\n","You've seen the model build -- well, you haven't, really. \n","1. Copy the code above into the code section below and turn verbose on\n","2. Set the number of epochs to 10, so you don't have to wait so long\n","3. Observe how the loss function decreases over each epoch:"]},{"cell_type":"code","metadata":{"id":"xbFrOTmv09XL"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Gc1f9q1dEDAV"},"source":["Now let's test this on the test set and collect the results so we can inspect them at the end of this file:"]},{"cell_type":"code","metadata":{"id":"vyAVqluWugku"},"source":["test_results = {}\n","\n","test_results['age_model'] = age_model.evaluate(\n","    test_features['age'],\n","    test_labels, verbose=0)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MGckOL4OuqAH"},"source":["This is a regression with a single variable--way too simplistic for our purposes! On to bigger and better things!"]},{"cell_type":"markdown","metadata":{"id":"PyAIVER5vfNS"},"source":["## **3.2 REGRESSION: Using Multiple Variables to Predict incomeUSD in a Simple Neural Network**"]},{"cell_type":"markdown","metadata":{"id":"Jbt4A31Yvrv-"},"source":["You can use an almost identical setup to make predictions based on multiple inputs. This model still does the same y - mx + b except that m is a matrix and b is a vector.\n","\n","This time, we use the Normalization layer that was adapted to the whole dataset."]},{"cell_type":"code","metadata":{"id":"DqIVUbsKv7Yu"},"source":["linear_model = tf.keras.Sequential([\n","    normalizer,\n","    layers.Dense(units=1)\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"baZH3g_CwK5K"},"source":["When you call the model, its weight matrices will be built. You can see that the kernel (the m in y = mx + b) has a shape of (8,1)."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PstTgNeawWRU","executionInfo":{"status":"ok","timestamp":1648864457906,"user_tz":240,"elapsed":122,"user":{"displayName":"Sonja Streuber","userId":"03872648719424952237"}},"outputId":"eb68e79d-6b91-4054-eb25-e8be0c18ac78"},"source":["linear_model.layers[1].kernel"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Variable 'dense_1/kernel:0' shape=(8, 1) dtype=float32, numpy=\n","array([[-0.10615379],\n","       [ 0.7392769 ],\n","       [-0.47365597],\n","       [ 0.05857676],\n","       [ 0.07512254],\n","       [ 0.3038857 ],\n","       [ 0.25790393],\n","       [ 0.48096907]], dtype=float32)>"]},"metadata":{},"execution_count":30}]},{"cell_type":"markdown","metadata":{"id":"diKM-dKTwdho"},"source":["Now, we configure the model's runtime execution with the same compile and fit calls as for the single input age model:"]},{"cell_type":"code","metadata":{"id":"_wO8dfkkwhvI"},"source":["linear_model.compile(\n","    optimizer=tf.optimizers.Adam(learning_rate=0.1),\n","    loss='mean_absolute_error')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":571},"id":"KKKIMHS9wput","executionInfo":{"status":"error","timestamp":1648864476136,"user_tz":240,"elapsed":13428,"user":{"displayName":"Sonja Streuber","userId":"03872648719424952237"}},"outputId":"0782ef6e-c29e-45cf-8d07-241a2ae609c5"},"source":["%%time\n","history = linear_model.fit(\n","    train_features, train_labels, \n","    epochs=10,\n","    # 10 epochs, so we turn on logging\n","    verbose=1,\n","    # Calculate validation results on 20% of the training data\n","    validation_split = 0.2)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","652/652 [==============================] - 4s 5ms/step - loss: 56929.4961 - val_loss: 55725.9688\n","Epoch 2/10\n","652/652 [==============================] - 2s 4ms/step - loss: 56864.2227 - val_loss: 55661.0195\n","Epoch 3/10\n","652/652 [==============================] - 3s 4ms/step - loss: 56798.9531 - val_loss: 55596.0312\n","Epoch 4/10\n","652/652 [==============================] - 3s 4ms/step - loss: 56733.7148 - val_loss: 55531.0977\n","Epoch 5/10\n","455/652 [===================>..........] - ETA: 0s - loss: 56501.0664"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-32-3a8c00f66a8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'history = linear_model.fit(\\n    train_features, train_labels, \\n    epochs=10,\\n    # 10 epochs, so we turn on logging\\n    verbose=1,\\n    # Calculate validation results on 20% of the training data\\n    validation_split = 0.2)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<decorator-gen-53>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"e0myiyL-ydWy"},"source":["Just like before, we collect the results in the test_results variable again:"]},{"cell_type":"code","metadata":{"id":"9FlEqQxSyh9v"},"source":["test_results['linear_model'] = linear_model.evaluate(\n","    test_features, test_labels, verbose=0)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hj1wYh_qlsdS"},"source":["## Your Turn\n","What is the command to display the current contents of the test_results variable? Type it below and inspect the results! What do you see?"]},{"cell_type":"code","metadata":{"id":"s2KvxzFJluL1"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_KWik3H_ys0G"},"source":["## **3.3 REGRESSION: Deep Neural Network (DNN)**\n"]},{"cell_type":"markdown","metadata":{"id":"1fBO1pEHzCEQ"},"source":["The previous section implemented linear models for single and multiple inputs in a **Simple Neural Network.**\n","\n","\n","\n","This section implements single-input and multiple-input DNN models. The code is basically the same except **the model is expanded to include some \"hidden\" non-linear layers**. The name \"hidden\" here just means not directly connected to the inputs or outputs.\n","\n","These models will contain a few more layers than the linear model:\n","\n","1. The normalization layer (imagine this as hidden layer 1 in the graphic below)\n","2. Two hidden, nonlinear, Dense layers using the relu nonlinearity (hidden layers 2 and 3 in the graphic below)\n","3. A linear single-output layer because we are calculating ONE regression output.\n","\n","<div>\n","<center>\n","<img src=\"https://raw.githubusercontent.com/shstreuber/Data-Mining/master/images/deepnn_regression.png\" width=\"600\">\n","</div>\n","\n","Both will use the same training procedure so the compile method is included in the build_and_compile_model function below.\n","\n","###**Deep Neural Network Model Code Below**\n","Here it is! NOTE that now, we are building and configuring the layers!\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"-RUfA-v7zNCQ"},"source":["def build_and_compile_model(norm):\n","  model = keras.Sequential([                 # Here you are setting up the keras.Sequential architecture\n","      norm,                                  # This is the normalizer function we built before\n","      layers.Dense(64, activation='relu'),   # Here is the first hidden layer--64 nodes, built with the relu function\n","      layers.Dense(64, activation='relu'),   # Here is the second hidden layer, also built with the relu function\n","      layers.Dense(1)                        # Here is the Dense layer for a single output because we are working on a REGRESSION\n","  ])                                         # AND WE'RE DONE WITH BUILDING THE MODEL!\n","\n","  model.compile(loss='mean_absolute_error',   # Now we configure the runtime for our model; the loss function is mean absolute error--makes sense for a regression!\n","                optimizer=tf.keras.optimizers.Adam(0.001))\n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sNIsFYij0Kyd"},"source":["### **3.3.1 REGRESSION--One Variable**\n","As before, we use the age variable to predice incomeUSD"]},{"cell_type":"code","metadata":{"id":"WwTGLgmn0VLO"},"source":["dnn_age_model = build_and_compile_model(age_normalizer)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lZZKGCBX0d3U"},"source":["This model has quite a few more trainable parameters than the linear models."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QQUyjuXU0e0_","executionInfo":{"status":"ok","timestamp":1648864548541,"user_tz":240,"elapsed":148,"user":{"displayName":"Sonja Streuber","userId":"03872648719424952237"}},"outputId":"acd23d36-ffe0-41b6-8b9e-a5ce5f994148"},"source":["dnn_age_model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," normalization_1 (Normalizat  (None, 1)                3         \n"," ion)                                                            \n","                                                                 \n"," dense_2 (Dense)             (None, 64)                128       \n","                                                                 \n"," dense_3 (Dense)             (None, 64)                4160      \n","                                                                 \n"," dense_4 (Dense)             (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 4,356\n","Trainable params: 4,353\n","Non-trainable params: 3\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","metadata":{"id":"xTVf1W8-0m7s"},"source":["Now, we train the model:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pdNzp5h50tMO","executionInfo":{"status":"ok","timestamp":1648864565589,"user_tz":240,"elapsed":14461,"user":{"displayName":"Sonja Streuber","userId":"03872648719424952237"}},"outputId":"22165a82-0546-4852-c332-91df0c4d5d59"},"source":["%%time\n","history = dnn_age_model.fit(\n","    train_features['age'], train_labels,\n","    validation_split=0.2,\n","    verbose=1, epochs=10)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","652/652 [==============================] - 2s 2ms/step - loss: 55952.1562 - val_loss: 51683.7773\n","Epoch 2/10\n","652/652 [==============================] - 1s 2ms/step - loss: 42762.7148 - val_loss: 29643.2031\n","Epoch 3/10\n","652/652 [==============================] - 1s 2ms/step - loss: 28107.0312 - val_loss: 26094.0293\n","Epoch 4/10\n","652/652 [==============================] - 1s 2ms/step - loss: 27193.6426 - val_loss: 25895.6465\n","Epoch 5/10\n","652/652 [==============================] - 1s 2ms/step - loss: 27057.1426 - val_loss: 25801.7598\n","Epoch 6/10\n","652/652 [==============================] - 1s 2ms/step - loss: 26979.5117 - val_loss: 25747.4180\n","Epoch 7/10\n","652/652 [==============================] - 1s 2ms/step - loss: 26933.0332 - val_loss: 25719.2070\n","Epoch 8/10\n","652/652 [==============================] - 1s 2ms/step - loss: 26906.4297 - val_loss: 25705.4609\n","Epoch 9/10\n","652/652 [==============================] - 1s 2ms/step - loss: 26892.7168 - val_loss: 25692.8945\n","Epoch 10/10\n","652/652 [==============================] - 1s 2ms/step - loss: 26880.3809 - val_loss: 25686.7109\n","CPU times: user 15.8 s, sys: 1.04 s, total: 16.8 s\n","Wall time: 14.3 s\n"]}]},{"cell_type":"code","source":["train_labels"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"taPL4VmJ_CwI","executionInfo":{"status":"ok","timestamp":1648864573485,"user_tz":240,"elapsed":141,"user":{"displayName":"Sonja Streuber","userId":"03872648719424952237"}},"outputId":"22517ed1-0616-42ca-c559-6c7414bcd6ab"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["22278     27267\n","8950      26135\n","7838      46605\n","16505     30635\n","19140    189367\n","          ...  \n","12877     29038\n","13288     34232\n","2751      44265\n","11903     41255\n","17632     22011\n","Name: incomeUSD, Length: 26049, dtype: int64"]},"metadata":{},"execution_count":38}]},{"cell_type":"markdown","metadata":{"id":"qiwtPeLJB7lQ"},"source":["And we plot the outcomes:"]},{"cell_type":"code","metadata":{"id":"-kuceR4fB-ig"},"source":["x = tf.linspace(0.0, 250, 251)\n","y = dnn_age_model.predict(x)\n","\n","plot_age(x, y)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"c7V2XJz7CMDO"},"source":["Wow! Our model does a much better job! But is it a good job? Not yet."]},{"cell_type":"markdown","metadata":{"id":"xUpPmDiK0-JQ"},"source":["And we collect the test results:"]},{"cell_type":"code","metadata":{"id":"To9dY4na1Bbt"},"source":["test_results['dnn_age_model'] = dnn_age_model.evaluate(\n","    test_features['age'], test_labels,\n","    verbose=0)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Y-Gwu9xw1Qz7"},"source":["### **3.3.2 REGRESSION: Multiple Variables**\n","If you repeat this process using all the inputs it slightly improves the performance on the validation dataset."]},{"cell_type":"code","metadata":{"id":"HVS07zOT1efm"},"source":["dnn_model = build_and_compile_model(normalizer)\n","dnn_model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_ob1LsbR1oZx"},"source":["%%time\n","history = dnn_model.fit(\n","    train_features, train_labels,\n","    validation_split=0.2,\n","    verbose=1, epochs=10)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"R6T-OKdlCkU5"},"source":["Let's see if our predictions come closer to the actual data distribution (run the code below to see the graph):"]},{"cell_type":"code","source":["%%time\n","history = dnn_model.fit(\n","    train_features, train_labels,\n","    validation_split=0.2,\n","    verbose=1, epochs=0)"],"metadata":{"id":"QHlfTHh9u3Z6"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Sj4ILEYiCplW"},"source":["test_predictions = dnn_model.predict(test_features).flatten()\n","\n","a = plt.axes(aspect='equal')\n","plt.scatter(test_labels, test_predictions)\n","plt.xlabel('True Values [incomeUSD]')\n","plt.ylabel('Predictions [incomeUSD]')\n","lims = [0, 50]\n","plt.xlim(lims)\n","plt.ylim(lims)\n","_ = plt.plot(lims, lims)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NJXY2BDz5Qle"},"source":["Now we can predict our test values"]},{"cell_type":"code","metadata":{"id":"MlEGGb5Z5Re0"},"source":["test_predictions = dnn_model.predict(test_features).flatten()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cTOKbKxG128Z"},"source":["As before, we collect the results on the test set in our test_results variable:"]},{"cell_type":"code","metadata":{"id":"B6RZVlWq15-d"},"source":["test_results['dnn_model'] = dnn_model.evaluate(test_features, test_labels, verbose=0)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"irE3Vbjb2DD7"},"source":["# **4. Comparing all 4 models**\n","Now that all the models are trained check the test-set performance and see how they did:"]},{"cell_type":"code","metadata":{"id":"Q6t4bb2s5wtr"},"source":["pd.DataFrame(test_results, index=['Mean absolute error [incomeUSD]']).T"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mmV-zMhE2XUw"},"source":["## Your Turn\n","\n","Which model performs the best? If you think about how each of the 4 models was built, why does your chosen model perform best?"]},{"cell_type":"markdown","metadata":{"id":"MoTgQPR62hlR"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"9Q6RPwex77sa"},"source":["#SOLUTIONS\n","To help you get unstuck:"]},{"cell_type":"code","metadata":{"id":"LuYUvBmv7ay9"},"source":["# This is the solution for task 2.1 above\n","\n","adult_dl = pd.DataFrame(adult, columns = ['age', 'educationyears', 'race','hoursperweek','incomeUSD'])\n","adult_dl.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JQtSMqLEyQSe"},"source":["adult_dl.race.unique()"],"execution_count":null,"outputs":[]}]}